%%
%% reference.bib
%% 
%% BibTeX database for IROS 2026 paper
%%
%% Add your references here following the BibTeX format.
%% For IEEE style references, see IEEEexample.bib for examples.
%%

% =============================================================================
% Example entries (remove or modify as needed)
% =============================================================================

@inproceedings{VLN_servey1,
   title={Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future Directions},
   url={http://dx.doi.org/10.18653/v1/2022.acl-long.524},
   DOI={10.18653/v1/2022.acl-long.524},
   booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   publisher={Association for Computational Linguistics},
   author={Gu, Jing and Stefani, Eliana and Wu, Qi and Thomason, Jesse and Wang, Xin},
   year={2022},
   pages={7606–7623} 
}

@misc{VLN_servey2,
      title={Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments}, 
      author={Peter Anderson and Qi Wu and Damien Teney and Jake Bruce and Mark Johnson and Niko Sünderhauf and Ian Reid and Stephen Gould and Anton van den Hengel},
      year={2018},
      eprint={1711.07280},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1711.07280}, 
}

@misc{VL_Nav,
      title={VL-Nav: Real-time Vision-Language Navigation with Spatial Reasoning}, 
      author={Yi Du and Taimeng Fu and Zhuoqun Chen and Bowen Li and Shaoshu Su and Zhipeng Zhao and Chen Wang},
      year={2025},
      eprint={2502.00931},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2502.00931}, 
}

@misc{IROS_VLN,
      title={IROS: A Dual-Process Architecture for Real-Time VLM-Based Indoor Navigation}, 
      author={Joonhee Lee and Hyunseung Shin and Jeonggil Ko},
      year={2026},
      eprint={2601.21506},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2601.21506}, 
}

@misc{HIAI,
      title={Harnessing Input-Adaptive Inference for Efficient VLN}, 
      author={Dongwoo Kang and Akhil Perincherry and Zachary Coalson and Aiden Gabriel and Stefan Lee and Sanghyun Hong},
      year={2025},
      eprint={2508.09262},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2508.09262}, 
}


@misc{efficientvln,
      title={Efficient-VLN: A Training-Efficient Vision-Language Navigation Model}, 
      author={Duo Zheng and Shijia Huang and Yanyang Li and Liwei Wang},
      year={2025},
      eprint={2512.10310},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.10310}, 
}

@misc{etp_r1,
      title={ETP-R1: Evolving Topological Planning with Reinforcement Fine-tuning for Vision-Language Navigation in Continuous Environments}, 
      author={Shuhao Ye and Sitong Mao and Yuxiang Cui and Xuan Yu and Shichao Zhai and Wen Chen and Shunbo Zhou and Rong Xiong and Yue Wang},
      year={2025},
      eprint={2512.20940},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2512.20940}, 
}

@misc{LOGNav,
      title={LOG-Nav: Efficient Layout-Aware Object-Goal Navigation with Hierarchical Planning}, 
      author={Jiawei Hou and Yuting Xiao and Xiangyang Xue and Taiping Zeng},
      year={2025},
      eprint={2505.06131},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2505.06131}, 
}

@misc{StreamVLN,
      title={StreamVLN: Streaming Vision-and-Language Navigation via SlowFast Context Modeling}, 
      author={Meng Wei and Chenyang Wan and Xiqian Yu and Tai Wang and Yuqiang Yang and Xiaohan Mao and Chenming Zhu and Wenzhe Cai and Hanqing Wang and Yilun Chen and Xihui Liu and Jiangmiao Pang},
      year={2025},
      eprint={2507.05240},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2507.05240}, 
}

@misc{MiniVLN,
      title={MiniVLN: Efficient Vision-and-Language Navigation by Progressive Knowledge Distillation}, 
      author={Junyou Zhu and Yanyuan Qiao and Siqi Zhang and Xingjian He and Qi Wu and Jing Liu},
      year={2024},
      eprint={2409.18800},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.18800}, 
}

@misc{NaVILA,
      title={NaVILA: Legged Robot Vision-Language-Action Model for Navigation}, 
      author={An-Chieh Cheng and Yandong Ji and Zhaojing Yang and Zaitian Gongye and Xueyan Zou and Jan Kautz and Erdem Bıyık and Hongxu Yin and Sifei Liu and Xiaolong Wang},
      year={2025},
      eprint={2412.04453},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2412.04453}, 
}


@misc{Uni-NaVid,
      title={Uni-NaVid: A Video-based Vision-Language-Action Model for Unifying Embodied Navigation Tasks}, 
      author={Jiazhao Zhang and Kunyu Wang and Shaoan Wang and Minghan Li and Haoran Liu and Songlin Wei and Zhongyuan Wang and Zhizheng Zhang and He Wang},
      year={2025},
      eprint={2412.06224},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2412.06224}, 
}

@misc{NAPVLN,
      title={Walk and Read Less: Improving the Efficiency of Vision-and-Language Navigation via Tuning-Free Multimodal Token Pruning}, 
      author={Wenda Qin and Andrea Burns and Bryan A. Plummer and Margrit Betke},
      year={2025},
      eprint={2509.15250},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2509.15250}, 
}

@misc{NavEE,
      title={Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving}, 
      author={Haibo Hu and Lianming Huang and Xinyu Wang and Yufei Cui and Shangyu Wu and Nan Guan and Chun Jason Xue},
      year={2025},
      eprint={2510.01795},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2510.01795}, 
}

@misc{vlacache,
      title={VLA-Cache: Efficient Vision-Language-Action Manipulation via Adaptive Token Caching}, 
      author={Siyu Xu and Yunke Wang and Chenghao Xia and Dihao Zhu and Tao Huang and Chang Xu},
      year={2025},
      eprint={2502.02175},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2502.02175}, 
}

@misc{token_merging,
      title={Token Merging: Your ViT But Faster}, 
      author={Daniel Bolya and Cheng-Yang Fu and Xiaoliang Dai and Peizhao Zhang and Christoph Feichtenhofer and Judy Hoffman},
      year={2023},
      eprint={2210.09461},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2210.09461}, 
}

@misc{stcache,
      title={Prune Spatio-temporal Tokens by Semantic-aware Temporal Accumulation}, 
      author={Shuangrui Ding and Peisen Zhao and Xiaopeng Zhang and Rui Qian and Hongkai Xiong and Qi Tian},
      year={2023},
      eprint={2308.04549},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2308.04549}, 
}

@misc{token_sparsification,
      title={Making Vision Transformers Efficient from A Token Sparsification View}, 
      author={Shuning Chang and Pichao Wang and Ming Lin and Fan Wang and David Junhao Zhang and Rong Jin and Mike Zheng Shou},
      year={2023},
      eprint={2303.08685},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2303.08685}, 
}

@misc{EgoPrune,
      title={EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent}, 
      author={Jiaao Li and Kaiyuan Li and Chen Gao and Yong Li and Xinlei Chen},
      year={2025},
      eprint={2507.15428},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.15428}, 
}

@misc{View_Invariant_Learning,
      title={View Invariant Learning for Vision-Language Navigation in Continuous Environments}, 
      author={Josh Qixuan Sun and Xiaoying Xing and Huaiyuan Weng and Chul Min Yeum and Mark Crowley},
      year={2025},
      eprint={2507.08831},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.08831}, 
}


@misc{ST-Booster,
      title={ST-Booster: An Iterative SpatioTemporal Perception Booster for Vision-and-Language Navigation in Continuous Environments}, 
      author={Lu Yue and Dongliang Zhou and Liang Xie and Erwei Yin and Feitian Zhang},
      year={2025},
      eprint={2504.09843},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.09843}, 
}

@misc{GVLN,
      title={Ground-level Viewpoint Vision-and-Language Navigation in Continuous Environments}, 
      author={Zerui Li and Gengze Zhou and Haodong Hong and Yanyan Shao and Wenqi Lyu and Yanyuan Qiao and Qi Wu},
      year={2025},
      eprint={2502.19024},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2502.19024}, 
}

@misc{Nipping,
      title={Nipping the Drift in the Bud: Retrospective Rectification for Robust Vision-Language Navigation}, 
      author={Gang He and Zhenyang Liu and Kepeng Xu and Li Xu and Tong Qiao and Wenxin Yu and Chang Wu and Weiying Xie},
      year={2026},
      eprint={2602.06356},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2602.06356}, 
}

@misc{Dynamic_Topology_Awareness,
      title={Dynamic Topology Awareness: Breaking the Granularity Rigidity in Vision-Language Navigation}, 
      author={Jiankun Peng and Jianyuan Guo and Ying Xu and Yue Liu and Jiashuang Yan and Xuanwei Ye and Houhua Li and Xiaoming Wang},
      year={2026},
      eprint={2601.21751},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2601.21751}, 
}

@misc{Learn_VLA_cache,
      title={Learning to Accelerate Vision-Language-Action Models through Adaptive Visual Token Caching}, 
      author={Yujie Wei and Jiahan Fan and Jiyu Guo and Ruichen Zhen and Rui Shao and Xiu Su and Zeke Xie and Shuo Yang},
      year={2026},
      eprint={2602.00686},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2602.00686}, 
}

@misc{Efficient_VLA_cache,
      title={Efficient Long-Horizon Vision-Language-Action Models via Static-Dynamic Disentanglement}, 
      author={Weikang Qiu and Tinglin Huang and Aosong Feng and Rex Ying},
      year={2026},
      eprint={2602.03983},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2602.03983}, 
}

@misc{KV-Efficient,
      title={KV-Efficient VLA: A Method to Speed up Vision Language Models with RNN-Gated Chunked KV Cache}, 
      author={Wanshun Xu and Long Zhuang and Lianlei Shan},
      year={2025},
      eprint={2509.21354},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2509.21354}, 
}

@misc{Intern-n1,
      title={Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language Navigation}, 
      author={Meng Wei and Chenyang Wan and Jiaqi Peng and Xiqian Yu and Yuqiang Yang and Delin Feng and Wenzhe Cai and Chenming Zhu and Tai Wang and Jiangmiao Pang and Xihui Liu},
      year={2025},
      eprint={2512.08186},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2512.08186}, 
}